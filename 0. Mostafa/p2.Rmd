---
title: "p2"
author: "Mostafa"
date: "04/25/2023"
output:
    html_notebook: 
        toc: yes
        toc_float: yes
---

# Problem 2    

[50 points]

We will use the api data again for this problem, but this time we are interested in predicting the api test scores for 2000 (i.e. api00) based on a battery of school, teacher and parent information. This time the data and models are available in the apipopProb2.RData R workspace. Note the data sets here are different than for Problem 1.   

For this problem, you are given three models that aim at predicting **api00** (R objects model1 â€“ model3), using different methods (i.e., CART, XGBoost, OLS regression). Utilize the following interpretation techniques with the training data to learn more about how those models were trained. Specifically for each of the models you should:   

## Libraries

```{r}
rm(list = ls())

suppressPackageStartupMessages(library(randomForest)) # Random Forest
suppressPackageStartupMessages(library(pdp)) # pdp
suppressPackageStartupMessages(library(ggplot2)) # ggplot2
suppressPackageStartupMessages(library(iml)) # iml
suppressPackageStartupMessages(library(kableExtra)) # kableExtra
suppressPackageStartupMessages(library(knitr)) # needed for the kable function
suppressPackageStartupMessages(library(ICEbox))

suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(grid))
suppressPackageStartupMessages(library(gridExtra))
suppressPackageStartupMessages(library(lattice))
suppressPackageStartupMessages(library(xgboost))
suppressPackageStartupMessages(library(glmnet))
suppressPackageStartupMessages(library(rpart))
```

## Dataset

```{r}
load("./data/external/apipopProb2.RData")
```

## Functions

### PDP1var function

```{r}
PDP1var <- function(model1, var1) {

    pd1 <- partial(model1, 
                   pred.var = var1, 
                   plot = TRUE, 
                   rug = TRUE
                   ) 
    
    pd1a <- partial(model1, 
                    pred.var = var1, 
                    plot = TRUE, 
                    plot.engine="ggplot2"
                    ) 
    
    pd1a <- pd1a + ggtitle("ggplot2-based PDP") 
    
    grid.arrange(pd1, 
                 pd1a, 
                 ncol=2
                 )

}
```

### PDP2var function

```{r}
PDP2var <- function(model1, var1, var2) {
    
    pdp12 <-  partial(model1, 
                      pred.var = c(var1, var2), 
                      plot = TRUE, 
                      chull = TRUE, 
                      palette = "magma"
                      )
    pdp12
}
```

### ALE function

```{r}
ALE <- function(model1, feature1, data1, response1){
  
    predictor1 <- Predictor$new(model = model1, 
                                data = data1, 
                                y = response1
                                )
    
    pdp1  <- FeatureEffect$new(predictor1, 
                               feature=feature1, 
                               method="pdp"
                               ) 
    
    ale1  <- FeatureEffect$new(predictor1, 
                               feature=feature1
                               ) 
    
    grid.arrange(ale1$plot(), 
                 pdp1$plot(), 
                 ncol=2
                 )
}
```

### Interaction_overall function

```{r}
Interaction_overall <- function(model1, data1, response1) {
    
    predictor1 <- Predictor$new(model1, 
                                data = data1, 
                                y = response1
                                )
    interact <- Interaction$new(predictor1)
    plot(interact)
}
```

### Interaction_feature_specific function

```{r}
Interaction_feature_specific <- function(model1, data1, response1, feature1) {
    
    predictor1 <- Predictor$new(model1, 
                                data = data1, 
                                y = response1
                                )
    interact <- Interaction$new(predictor1,
                                feature = feature1
                                )
    plot(interact)
}
```

## a. Partial Dependence plots 1-var   

Produce Partial Dependence plots for the most important predictor of each model.

### model1: Generalized Linear Model

**Interpretation**:      
A steep straight decline which means a strong negative relationship between "yhat" and "meals".

```{r}
varImp(model1, scale = FALSE)
PDP1var(model1, "meals")
```

### model2: CART

**Interpretation**:      

The curve on the Partial Dependence Plot (PDP) appears as a step function, with flat regions separated by sharp jumps downward, it suggests that there may be specific values of the predictor variable (not.hsg) that are particularly important in determining the predicted outcome (yhat).    

```{r}
varImp(model2, scale = FALSE)
PDP1var(model2, "not.hsg")
```

### model3: eXtreme Gradient Boosting

**Interpretation**:      

The curve on a Partial Dependence Plot (PDP) is declining overall but has local ups and downs, it suggests:    

1. There may be a non-linear relationship between the predictor variable and the predicted outcome. These local deviations could represent interactions between the predictor variable and other features in the model, or they could suggest that there are specific ranges of the predictor variable where it has a stronger or weaker impact on the predicted outcome.     

2. It's also possible that the local ups and downs in the curve are simply due to noise in the data or limitations of the model. In this case, it's important to carefully evaluate the quality of the data and the appropriateness of the modeling approach to ensure that the PDP accurately represents the relationship between the predictor variable and the predicted outcome.   

```{r}
varImp(model3, scale = FALSE)
PDP1var(model3, "meals")
```

## b. Partial Dependence plots 2-var  

Produce Partial Dependence plots for the two most important predictors of each model (i.e., 3D plots or heatmaps or contour plots).

### model1: Generalized Linear Model

**Interpretation**:      

This type of relationship is known as a U-shaped relationship, where the predicted outcome is highest when both variables are at low levels, decreases as one or both variables increase, and then may increase again at higher levels of both variables. It suggests that there may be a nonlinear relationship between the two predictor variables and the target variable.    

The slightly increasing slope of the plot suggests that the effect of the predictor variables on the predicted outcome is becoming slightly stronger as the values of the predictor variables increase. However, the U-shaped relationship suggests that there may be other factors at play that are causing the decrease in the predicted outcome as the values of the predictor variables increase.   

```{r}
varImp(model1, scale = FALSE)
PDP2var(model1, "meals", "ell")
```

### model2: CART

**Interpretation**:      

The decreasing slope suggests that as one predictor variable increases, the effect of the other predictor variable on the predicted outcome is becoming weaker. This is indicative of an interaction effect, where the effect of one predictor variable depends on the value of the other predictor variable.     

The fact that the z-axis is highest when the y-axis is high and the x-axis is low, and lowest when the y-axis is low and the x-axis is high, suggests that the two predictor variables are working in opposite directions. This means that when one predictor variable is high and the other is low, the predicted outcome is high, while the predicted outcome is low when the values are reversed.     

```{r}
varImp(model2, scale = FALSE)
PDP2var(model1, "not.hsg", "avg.ed")
```

### model3: eXtreme Gradient Boosting   

**Interpretation**:      

The slightly decreasing slope suggests that the interaction effect is weaker than in the case where the slope is strictly decreasing. However, it still suggests that as one predictor variable increases, the effect of the other predictor variable on the predicted outcome is becoming weaker.     

The fact that the z-axis is highest when the y-axis is high and the x-axis is low, and lowest when the y-axis is low and the x-axis is high, suggests that the two predictor variables are working in opposite directions. This means that when one predictor variable is high and the other is low, the predicted outcome is high, while the predicted outcome is low when the values are reversed.    

```{r}
varImp(model3, scale = FALSE)
PDP2var(model1, "meals", "avg.ed")
```

## c. ALE plots     

- Produce Accumulated Local Effects plots for the most important predictor in each model.     
- How do these plots vary from those produced in part b? Given the correlation structure in the apipop_train data is it surprising or not that these plots differ or are similar to each other.

### model1: Generalized Linear Model   

**Interpretation**:      

It suggests a negative relationship between the predictor variable (x-axis) and the predicted outcome (y-axis). This means that as the value of the predictor variable increases, the predicted outcome decreases.     

The decreasing slope of the ALE plot suggests that the relationship between the predictor variable and the predicted outcome is becoming weaker as the value of the predictor variable increases. This is consistent with the decreasing ALE of y and predicted y values with increasing x-axis values.    

```{r}
varImp(model1, scale = FALSE)

ALE(model1, 
    "meals", 
    apipop_train, 
    apipop_train$api00
    )
```

### model2: CART     

**Interpretation**:      

It suggests that the relationship between the predictor variable and the predicted outcome is not linear. Instead, there may be discrete intervals or steps where the effect of the predictor variable on the predicted outcome changes.   

The step-like pattern in the ALE plot suggests that the relationship between the predictor variable and the predicted outcome may be due to different factors or conditions that affect the outcome. For example, there may be different subgroups or categories of observations that have different relationships between the predictor variable and the predicted outcome.    

```{r}
varImp(model2, scale = FALSE)

ALE(model2, 
    "not.hsg", 
    apipop_train, 
    apipop_train$api00
    )
```

### model3: eXtreme Gradient Boosting     

**Interpretation**:      

It suggests that the relationship between the predictor variable and the predicted outcome is not linear and may have some non-monotonic behavior.

The ups and downs in the ALE plot indicate that the relationship between the predictor variable and the predicted outcome may change direction or magnitude at certain values of the predictor variable. This non-monotonic behavior can arise due to complex interactions or nonlinear relationships between the predictor variable and other variables in the model.     

In this case, it may be useful to investigate the data further to identify the factors that contribute to the non-monotonic behavior. This could involve examining other variables that may interact with the predictor variable, or exploring subgroups or categories of observations that have different relationships with the predictor variable.    

```{r}
varImp(model3, scale = FALSE)

ALE(model3, 
    "meals", 
    apipop_train, 
    apipop_train$api00
    )
```

## d. Interaction plots   

- Compute the overall interaction H statistics     
- as well as the feature specific statistics for the **ELL variable** for all of the models.    
- Provide a table that includes as rows the predictors in the apipop_train data file and the H statistics for each model as columns.     
- For the ELL specific H statistics, provide an interaction plot per model.

### model1: Generalized Linear Model

```{r}
Interaction_overall(model1, 
                    apipop_train, 
                    apipop_train$api00
                    )
```

```{r}
Interaction_feature_specific(model1, 
                             apipop_train, 
                             apipop_train$api00,
                             "ell"
                             )
```

### model2: CART

```{r}
Interaction_overall(model2, 
                    apipop_train, 
                    apipop_train$api00
                    )
```

```{r}
Interaction_feature_specific(model2, 
                             apipop_train, 
                             apipop_train$api00,
                             "ell"
                             )
```

### model3: eXtreme Gradient Boosting

```{r}
Interaction_overall(model3, 
                    apipop_train, 
                    apipop_train$api00
                    )
```

```{r}
Interaction_feature_specific(model3, 
                             apipop_train, 
                             apipop_train$api00,
                             "ell"
                             )
```

## e. Prediction performance    

Evaluate the prediction performance of each model using the test set that is included in the workspace (e.g. apipop_test).

### model1: Generalized Linear Model

```{r}
# prediction on test data
yhat <- predict(model1, s = model1, apipop_test)
# RMSE for test data
error.test <- yhat - apipop_test$api00
rmse.test <- sqrt(mean(error.test^2))
rmse.test
```

### model2: CART

```{r}
# prediction on test data
yhat <- predict(model1, s = model2, apipop_test)
# RMSE for test data
error.test <- yhat - apipop_test$api00
rmse.test <- sqrt(mean(error.test^2))
rmse.test
```

### model3: eXtreme Gradient Boosting

```{r}
# prediction on test data
yhat <- predict(model3, s = model1, apipop_test)
# RMSE for test data
error.test <- yhat - apipop_test$api00
rmse.test <- sqrt(mean(error.test^2))
rmse.test
```


## f. Conclusion    

Considering the results for the tasks above, which model object belongs to which method? Explain your choice!

- model1: Generalized Linear Model (GLM) typically produces a model object of class "glm", which contains information about the model coefficients, standard errors, and various goodness-of-fit measures.    

- model2: Classification and Regression Trees (CART) typically produces a model object of class "rpart", which contains information about the decision tree structure and splitting rules.    

- model3: eXtreme Gradient Boosting (XGBoost) typically produces a model object of class "xgb.Booster", which contains information about the gradient boosting model parameters, feature importance, and the learned ensemble of decision trees.
It is important to note that the specific properties of each model object may vary depending on the implementation and tuning choices made for each method.    

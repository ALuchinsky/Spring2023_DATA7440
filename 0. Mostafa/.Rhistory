dfm = dfm %>% mutate(count_out=replace(count_out, is.na(count_out), 0))
dfm$N_Present = dfm$count_in - dfm$count_out
dfm2 = merge(
dft1,
dfm[, c("dtin", "N_Present")],
by="dtin",
all.x=TRUE,
sort=FALSE
)
dfm2 = dfm2[, c("Academic_year", "Semester", "Semester_week", "dtin", "dtout", "Day_week", "Hour_in", "Hour_out", "N_Present")]
library("data.table")
setnames(dfm2,
new = c("Chech_in", "Check_out"),
old = c("dtin", "dtout"))
# We need to merge entrance and exit counters based on check_in and check_out timestamp,
#   but the problem is that some of the timestamps are present just in check_in (dtin) column,
#                       and some of the timestamps are present just in check_out (dtout) column.
#     So, we will have some NAs in the merged dataset (dfm).
#
# Solution:
#
#     Step 1: We order dfm based on dtin because end of the day we must calculate N_Present
#                 based on check_in timestamp (dtin).
#
#     Step 2: We fill the NAs downward which make sense.
#                 Because nothing has changed on that timestamp on that column.
#         Ex: 10:29   9     10:29   5         10:29   9     10:29   5
#             10:30   10                ==>   10:30   10    10:30   5
#                           10:31   7         10:31   10    10:31   7
#
#     Step 3: We need to drop duplicated based on dtin and keep the last row
#                 for this scenario that more than one student come in at the same timestamp.
#         Ex: 10:30   10    10:30   ...(whatever)
#             10:30   11    10:30   ...(whatever)  ==>
#             10:30   12    10:30   ...(whatever)       10:30   12    10:30   ...(whatever)
#
#     Step 4: We need to fill the first few rows of count_out with zero.
#                 Because for the first few timestamps there are still some NAs in dtout column.
#                 Because we we filled the NAs downward.
#         Ex: 7:29    1     7:29   NA         7:29   1    7:29   0
#             7:30    2     7:30   NA   ==>   7:30   2    7:30   0
#             7:31    3     7:31   1          7:31   3    7:31   1
#
#
#     Step 5: To calculate N_present by subtracting cumulative count_out from count_in
#                 at each timestamp.
#
#     Step 6: Cleaning the merged dataset.
library(tidyr)
dfm = merge(
dfin,
dfout,
by.x="dtin",
by.y="dtout",
all=TRUE
)
dfm = dfm[order(dfm$dtin),]
dfm = dfm %>% fill(c("count_in", "count_out"), .direction="down")
dfm = dfm[!duplicated(dfm$dtin, fromLast=TRUE), ]
dfm = dfm %>% mutate(count_out=replace(count_out, is.na(count_out), 0))
dfm$N_Present = dfm$count_in - dfm$count_out
dfm2 = merge(
dft1,
dfm[, c("dtin", "N_Present")],
by="dtin",
all.x=TRUE,
sort=FALSE
)
# To rearrange the columns
dfm2 = dfm2[, c("Academic_year", "Semester", "Semester_week", "dtin", "dtout", "Day_week", "Hour_in", "Hour_out", "N_Present")]
library("data.table")
setnames(dfm2,
new = c("Chech_in", "Check_out"),
old = c("dtin", "dtout"))
yhat = predict(rfFit, newdata=training)
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding")
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
index_training = which(dfm2$Academic_year=="F2016-S2017" )
training = dfm2[index_training, ]
index_testing = which(dfm2$Academic_year=="F2017-S2018")
testing = dfm2[index_testing, ]
# Sanity chack
# table(dfm2$Academic_year)
# nrow(dfm2) == nrow(training) + nrow(testing)
# Parallel computing
library(parallel)
nCores = detectCores() # Detect the number of CPU cores
if (.Platform$OS.type=='unix'){
library(doMC)
registerDoMC(nCores-1) # number of cores to register
}else{
library(doParallel) # for windows
cl = makePSOCKcluster(nCores-1) # number of cores to register
registerDoParallel(cl)
}
# Parallel computing
library(parallel)
nCores = detectCores() # Detect the number of CPU cores
if (.Platform$OS.type=='unix'){
library(doMC)
registerDoMC(nCores-1) # number of cores to register
}else{
library(doParallel) # for windows
cl = makePSOCKcluster(nCores-1) # number of cores to register
registerDoParallel(cl)
}
# Parallel computing
library(parallel)
nCores = detectCores() # Detect the number of CPU cores
if (.Platform$OS.type=='unix'){
library(doMC)
registerDoMC(nCores-1) # number of cores to register
}else{
library(doParallel) # for windows
cl = makePSOCKcluster(nCores-1) # number of cores to register
registerDoParallel(cl)
}
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding")
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(rfFit)
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding")
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(rfFit)
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(rfFit)
yhat = predict(rfFit, newdata=training)
rfTestMSE = mean((yhat - training[, "N_Present"])^2)
rfTestMSE
# variable importance scores
rfVarImp = varImp(rfFit)
rfVarImp$importance %>% arrange(desc(Overall)) %>% head(n=10) # top 10
# variable importance scores
rfVarImp = varImp(rfFit)
rfVarImp$importance %>% arrange(desc(Overall)) %>% head(n=4) # top 10
# variable importance scores
rfVarImp = varImp(rfFit)
rfVarImp$importance %>% arrange(desc(Overall)) %>% head(n=10) # top 10
# variable importance scores
rfVarImp = varImp(rfFit)
rfVarImp$importance %>% arrange(desc(Overall)) %>% head(n=20) # top 10
# variable importance scores
rfVarImp = varImp(rfFit)
rfVarImp$importance %>% arrange(desc(Overall)) %>% head(n=10) # top 10
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1)
gbmFit = train(N_Present ~ .,
data=training,
method='gbm', # uses `gbm` package
trControl=trCtrl,
tuneGrid=expand.grid(interaction.depth = 1:4,
n.trees = c(1000,3000,5000),
shrinkage = 0.2,
n.minobsinnode = 10
)
)
print(gbmFit)
# Tuning parameters:
# n.trees (# Boosting Iterations)
# interaction.depth (Max Tree Depth)
# shrinkage (Shrinkage)
# n.minobsinnode (Min. Terminal Node Size)
yhat = predict(gbmFit, newdata = training)
gbmTestMSE = mean((yhat - testing[,"N_Present" ])^2)
gbmTestMSE
yhat = predict(gbmFit, newdata = testing)
yhat = predict(rfFit, newdata=testing)
knitr::kable(data.frame(Tree=treeTestMSE,
RF=rfTestMSE,
Boosting=gbmTestMSE
),
align='c',
caption='Test MSE',
digits=2
)
knitr::kable(data.frame(#Tree=treeTestMSE,
RF=rfTestMSE,
Boosting=gbmTestMSE
),
align='c',
caption='Test MSE',
digits=2
)
# variable importance scores
gbmVarImp = varImp(gbmFit)
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print()
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(" ")
print(rfFit)
yhat = predict(rfFit, newdata=testing[ , c(Hour_in", "Day_week", "Semester", "Semester_week")])
yhat = predict(rfFit, newdata=testing[ , c("Hour_in", "Day_week", "Semester", "Semester_week")])
yhat = predict(rfFit, newdata=testing)
View(testing)
str(testing)
str(dfm2)
dfm2$Semester = as.factor(dfm2$Semester)
str(dfm2)
dfm2$N_Present = as.integer(dfm2$N_Present)
str(dfm2)
# Parallel computing
library(parallel)
nCores = detectCores() # Detect the number of CPU cores
if (.Platform$OS.type=='unix'){
library(doMC)
registerDoMC(nCores-1) # number of cores to register
}else{
library(doParallel) # for windows
cl = makePSOCKcluster(nCores-1) # number of cores to register
registerDoParallel(cl)
}
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(" ")
print(rfFit)
library(caret)
training = training[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
testing  =  testing[ , c("N_Present", "Hour_in", "Day_week", "Semester", "Semester_week")]
trCtrl = trainControl(method="cv",
number=10,
allowParallel=TRUE
)
RNGkind(sample.kind = "Rounding") # for reproducibility of set.seed() on different operation systems.
set.seed(1) # for reproducibility of results
nVar = ncol(training)-1
rfFit = train(Hour_in ~ .,
data=training,
method='rf', # uses `randomForest` package
trControl=trCtrl,
tuneGrid=data.frame(mtry=1:nVar),
ntree=100
)
print(" ")
print(rfFit)
yhat = predict(rfFit, newdata=testing)
rm(list = ls())
df0 = read.csv("Learning_Commons_Tutoring.csv")
## to explore the dataset
# View(df0)
# df0[!complete.cases(df0),] # check for missing data
# dim(df0)
# head(df0, 1)
# table(df0$Academic_year)
# table(df0$Semester)
# hist(df0$Semester_week)
View(df0)
# Wrong Dates
index_wrong_dates = which(df0$Check_in_date != df0$Check_out_date)
length(index_wrong_dates)
# Wrong times
index_wrong_times = which(df0$Check_in_time == df0$Check_out_time)
length(index_wrong_times)
# To drop the rows with wrong data or time
index_wrong_all = c(index_wrong_dates, index_wrong_times)
df1 = df0[-c(index_wrong_all), ]
# Sanity check
# length(index_wrong_all) == length(index_wrong_dates) + length(index_wrong_times)
# nrow(df0) - nrow(df1) == length(index_wrong_all)
View(df1)
# # The easiest way to get lubridate is to install the whole tidyverse:
# install.packages("tidyverse")
# # Alternatively, install just lubridate:
# install.packages("lubridate")
# # Cheatsheet: https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf
library(lubridate)
dft1 = df1
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_in_time_2 = paste(substr(df1$Check_in_time, 1, nchar(df1$Check_in_time)-2),
substr(df1$Check_in_time, nchar(df1$Check_in_time)-2+1, nchar(df1$Check_in_time)),
sep=":00 "
)
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_out_time_2 = paste(substr(df1$Check_out_time, 1, nchar(df1$Check_out_time)-2),
substr(df1$Check_out_time, nchar(df1$Check_out_time)-2+1, nchar(df1$Check_out_time)),
sep=":00 "
)
# Merge date and time columns
dft1$dtmid = paste(mdy(dft1$Check_in_date), "00:00:00 AM", sep=" ")
dft1$dtin = paste(mdy(dft1$Check_in_date), dft1$Check_in_time_2, sep=" ")
dft1$dtout = paste(mdy(dft1$Check_out_date), dft1$Check_out_time_2, sep=" ")
# Convert string to datetime format
dft1$dtmid = as_datetime(dft1$dtmid)
dft1$dtin = as_datetime(dft1$dtin)
dft1$dtout = as_datetime(dft1$dtout)
# Hour_in column by Converting 20:11:00 --> 20.183333
dft1$Hour_in = as.double(difftime(dft1$dtin, dft1$dtmid, units = "hours"))
# Hour_out column by Converting 20:11:00 --> 20.183333
dft1$Hour_out = as.double(difftime(dft1$dtout, dft1$dtmid, units = "hours"))
# Day_week column: Mon, Tue, ...
dft1$Day_week = wday(mdy(dft1$Check_in_date), label=TRUE)
dft1 = df1
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_in_time_2 = paste(substr(df1$Check_in_time, 1, nchar(df1$Check_in_time)-2),
substr(df1$Check_in_time, nchar(df1$Check_in_time)-2+1, nchar(df1$Check_in_time)),
sep=":00 "
)
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_out_time_2 = paste(substr(df1$Check_out_time, 1, nchar(df1$Check_out_time)-2),
substr(df1$Check_out_time, nchar(df1$Check_out_time)-2+1, nchar(df1$Check_out_time)),
sep=":00 "
)
# Merge date and time columns
dft1$dtmid = paste(mdy(dft1$Check_in_date), "00:00:00 AM", sep=" ")
dft1$dtin = paste(mdy(dft1$Check_in_date), dft1$Check_in_time_2, sep=" ")
dft1$dtout = paste(mdy(dft1$Check_out_date), dft1$Check_out_time_2, sep=" ")
# Convert string to datetime format
dft1$dtmid = as_datetime(dft1$dtmid)
dft1$dtin = as_datetime(dft1$dtin)
dft1$dtout = as_datetime(dft1$dtout)
# Hour_in column by Converting 20:11:00 --> 20.183333
dft1$Hour_in = as.double(difftime(dft1$dtin, dft1$dtmid, units = "hours"))
# Hour_out column by Converting 20:11:00 --> 20.183333
dft1$Hour_out = as.double(difftime(dft1$dtout, dft1$dtmid, units = "hours"))
# Day_week column: Mon, Tue, ...
dft1$Day_week = wday(mdy(dft1$Check_in_date), label=TRUE)
rm(list = ls())
df0 = read.csv("Learning_Commons_Tutoring.csv")
## to explore the dataset
# View(df0)
# df0[!complete.cases(df0),] # check for missing data
# dim(df0)
# head(df0, 1)
# table(df0$Academic_year)
# table(df0$Semester)
# hist(df0$Semester_week)
# Wrong Dates
index_wrong_dates = which(df0$Check_in_date != df0$Check_out_date)
length(index_wrong_dates)
# Wrong times
index_wrong_times = which(df0$Check_in_time == df0$Check_out_time)
length(index_wrong_times)
# To drop the rows with wrong data or time
index_wrong_all = c(index_wrong_dates, index_wrong_times)
df1 = df0[-c(index_wrong_all), ]
# Sanity check
# length(index_wrong_all) == length(index_wrong_dates) + length(index_wrong_times)
# nrow(df0) - nrow(df1) == length(index_wrong_all)
# # The easiest way to get lubridate is to install the whole tidyverse:
# install.packages("tidyverse")
# # Alternatively, install just lubridate:
# install.packages("lubridate")
# # Cheatsheet: https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf
library(lubridate)
dft1 = df1
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_in_time_2 = paste(substr(df1$Check_in_time, 1, nchar(df1$Check_in_time)-2),
substr(df1$Check_in_time, nchar(df1$Check_in_time)-2+1, nchar(df1$Check_in_time)),
sep=":00 "
)
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_out_time_2 = paste(substr(df1$Check_out_time, 1, nchar(df1$Check_out_time)-2),
substr(df1$Check_out_time, nchar(df1$Check_out_time)-2+1, nchar(df1$Check_out_time)),
sep=":00 "
)
# Merge date and time columns
dft1$dtmid = paste(mdy(dft1$Check_in_date), "00:00:00 AM", sep=" ")
dft1$dtin = paste(mdy(dft1$Check_in_date), dft1$Check_in_time_2, sep=" ")
dft1$dtout = paste(mdy(dft1$Check_out_date), dft1$Check_out_time_2, sep=" ")
# Convert string to datetime format
dft1$dtmid = as_datetime(dft1$dtmid)
dft1$dtin = as_datetime(dft1$dtin)
dft1$dtout = as_datetime(dft1$dtout)
# Hour_in column by Converting 20:11:00 --> 20.183333
dft1$Hour_in = as.double(difftime(dft1$dtin, dft1$dtmid, units = "hours"))
# Hour_out column by Converting 20:11:00 --> 20.183333
dft1$Hour_out = as.double(difftime(dft1$dtout, dft1$dtmid, units = "hours"))
# Day_week column: Mon, Tue, ...
dft1$Day_week = wday(mdy(dft1$Check_in_date), label=TRUE)
# Day_week column: Mon, Tue, ...
dft1$Day_week = wday(mdy(dft1$Check_in_date))
View(dft1)
# # The easiest way to get lubridate is to install the whole tidyverse:
# install.packages("tidyverse")
# # Alternatively, install just lubridate:
# install.packages("lubridate")
# # Cheatsheet: https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf
library(lubridate)
dft1 = df1
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_in_time_2 = paste(substr(df1$Check_in_time, 1, nchar(df1$Check_in_time)-2),
substr(df1$Check_in_time, nchar(df1$Check_in_time)-2+1, nchar(df1$Check_in_time)),
sep=":00 "
)
# Convert: "8:11PM" --> "8:11:00 PM"
dft1$Check_out_time_2 = paste(substr(df1$Check_out_time, 1, nchar(df1$Check_out_time)-2),
substr(df1$Check_out_time, nchar(df1$Check_out_time)-2+1, nchar(df1$Check_out_time)),
sep=":00 "
)
# Merge date and time columns
dft1$dtmid = paste(mdy(dft1$Check_in_date), "00:00:00 AM", sep=" ")
dft1$dtin = paste(mdy(dft1$Check_in_date), dft1$Check_in_time_2, sep=" ")
dft1$dtout = paste(mdy(dft1$Check_out_date), dft1$Check_out_time_2, sep=" ")
# Convert string to datetime format
dft1$dtmid = as_datetime(dft1$dtmid)
dft1$dtin = as_datetime(dft1$dtin)
dft1$dtout = as_datetime(dft1$dtout)
# Hour_in column by Converting 20:11:00 --> 20.183333
dft1$Hour_in = as.double(difftime(dft1$dtin, dft1$dtmid, units = "hours"))
# Hour_out column by Converting 20:11:00 --> 20.183333
dft1$Hour_out = as.double(difftime(dft1$dtout, dft1$dtmid, units = "hours"))
# Day_week column: Mon, Tue, ...
dft1$Day_week = wday(mdy(dft1$Check_in_date), label=TRUE)
source("C:/Users/Mostafa/Desktop/MP2-20230324T035929Z-001/MP2/Mostafa 2-MP-RF-Boosting.Rmd")
system.file("rmd_template/report.Rmd", package = "DataExplorer")
setwd("C:/Users/Mostafa/My Drive/2. Data_Science/4. 7440 Advanced Data Mining/Assignments/DATA7440 Final project")
